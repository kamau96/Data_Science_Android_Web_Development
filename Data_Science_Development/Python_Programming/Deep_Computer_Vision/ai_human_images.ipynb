{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10550636,"sourceType":"datasetVersion","datasetId":6412205}],"dockerImageVersionId":30886,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Detect AI vs Human generated images\nIn this notebook, I aim to build a convnet architecture for detecting real images from fake ones.","metadata":{}},{"cell_type":"code","source":"# All imports needed for this classification project\nimport kagglehub\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.applications import ResNet152, Xception\nfrom tensorflow.keras.applications.resnet import preprocess_input","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T09:38:17.922788Z","iopub.execute_input":"2025-02-27T09:38:17.923214Z","iopub.status.idle":"2025-02-27T09:38:35.650874Z","shell.execute_reply.started":"2025-02-27T09:38:17.923179Z","shell.execute_reply":"2025-02-27T09:38:35.649821Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# Global variables \nIMG_SIZE = 224\n\n# Reproducability\ndef set_seed(seed=44):\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\nset_seed()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T09:38:35.652162Z","iopub.execute_input":"2025-02-27T09:38:35.652698Z","iopub.status.idle":"2025-02-27T09:38:35.657981Z","shell.execute_reply.started":"2025-02-27T09:38:35.652671Z","shell.execute_reply":"2025-02-27T09:38:35.656637Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Download latest version\ndata_path = kagglehub.dataset_download(\"alessandrasala79/ai-vs-human-generated-dataset\")\n\nprint(\"Path to dataset files:\", data_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T09:38:35.660480Z","iopub.execute_input":"2025-02-27T09:38:35.660922Z","iopub.status.idle":"2025-02-27T09:38:35.784229Z","shell.execute_reply.started":"2025-02-27T09:38:35.660884Z","shell.execute_reply":"2025-02-27T09:38:35.783290Z"}},"outputs":[{"name":"stdout","text":"Path to dataset files: /kaggle/input/ai-vs-human-generated-dataset\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Csv files\ntrain = pd.read_csv(os.path.join(data_path,\"train.csv\"), index_col=0)\ntest = pd.read_csv(os.path.join(data_path, \"test.csv\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T09:38:35.785351Z","iopub.execute_input":"2025-02-27T09:38:35.785593Z","iopub.status.idle":"2025-02-27T09:38:35.967613Z","shell.execute_reply.started":"2025-02-27T09:38:35.785574Z","shell.execute_reply":"2025-02-27T09:38:35.966478Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"print(train.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T09:38:35.968855Z","iopub.execute_input":"2025-02-27T09:38:35.969192Z","iopub.status.idle":"2025-02-27T09:38:35.980810Z","shell.execute_reply.started":"2025-02-27T09:38:35.969167Z","shell.execute_reply":"2025-02-27T09:38:35.979807Z"}},"outputs":[{"name":"stdout","text":"                                         file_name  label\n0  train_data/a6dcb93f596a43249135678dfcfc17ea.jpg      1\n1  train_data/041be3153810433ab146bc97d5af505c.jpg      0\n2  train_data/615df26ce9494e5db2f70e57ce7a3a4f.jpg      1\n3  train_data/8542fe161d9147be8e835e50c0de39cd.jpg      0\n4  train_data/5d81fa12bc3b4cea8c94a6700a477cf2.jpg      1\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Create full path to the images\ntrain[\"file_name\"] = train[\"file_name\"].apply(lambda x: os.path.join(data_path, x))\ntest[\"id\"] = test[\"id\"].apply(lambda x: os.path.join(data_path, x))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T09:38:35.982092Z","iopub.execute_input":"2025-02-27T09:38:35.982471Z","iopub.status.idle":"2025-02-27T09:38:36.104116Z","shell.execute_reply.started":"2025-02-27T09:38:35.982442Z","shell.execute_reply":"2025-02-27T09:38:36.103206Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Split train into train and validation data\ntrain_ds, val_ds = train_test_split(train, test_size=0.2, random_state=44)\ntrain_ds = tf.data.Dataset.from_tensor_slices((train_ds[\"file_name\"].tolist(), train_ds[\"label\"]))\nval_ds = tf.data.Dataset.from_tensor_slices((val_ds[\"file_name\"].tolist(), val_ds[\"label\"]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T09:38:36.105042Z","iopub.execute_input":"2025-02-27T09:38:36.105353Z","iopub.status.idle":"2025-02-27T09:38:36.399214Z","shell.execute_reply.started":"2025-02-27T09:38:36.105327Z","shell.execute_reply":"2025-02-27T09:38:36.398219Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def load_resize_and_rescale(image_path, label):\n    image = tf.io.read_file(image_path)\n    image = tf.image.decode_jpeg(image, channels=3)\n    image = tf.cast(image, tf.float32)\n    image = tf.image.resize(image, [IMG_SIZE, IMG_SIZE])\n    image = (image / 255.0)\n    return image, label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T09:38:36.401852Z","iopub.execute_input":"2025-02-27T09:38:36.402202Z","iopub.status.idle":"2025-02-27T09:38:36.407501Z","shell.execute_reply.started":"2025-02-27T09:38:36.402174Z","shell.execute_reply":"2025-02-27T09:38:36.406276Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"def augment(image_label, seed):\n  image, label = image_label\n  image, label = load_resize_and_rescale(image, label)\n  image = tf.image.resize_with_crop_or_pad(image, IMG_SIZE + 6, IMG_SIZE + 6)\n  # Make a new seed.\n  new_seed = tf.random.split(seed, num=1)[0, :]\n  # Random crop back to the original size.\n  image = tf.image.stateless_random_crop(\n      image, size=[IMG_SIZE, IMG_SIZE, 3], seed=seed)\n  # Random brightness.\n  image = tf.image.stateless_random_brightness(\n      image, max_delta=0.5, seed=new_seed)\n  image = tf.clip_by_value(image, 0, 1)\n  return image, label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T09:38:36.408747Z","iopub.execute_input":"2025-02-27T09:38:36.409205Z","iopub.status.idle":"2025-02-27T09:38:36.427266Z","shell.execute_reply.started":"2025-02-27T09:38:36.409161Z","shell.execute_reply":"2025-02-27T09:38:36.426018Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# Create a `Counter` object and `Dataset.zip` it together with the training set.\ncounter = tf.data.experimental.Counter()\ntrain_ds = tf.data.Dataset.zip((train_ds, (counter, counter)))\nbatch_size = 32","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T09:38:36.428452Z","iopub.execute_input":"2025-02-27T09:38:36.428764Z","iopub.status.idle":"2025-02-27T09:38:36.484332Z","shell.execute_reply.started":"2025-02-27T09:38:36.428736Z","shell.execute_reply":"2025-02-27T09:38:36.483313Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"train_ds = (\n    train_ds\n    .shuffle(1000)\n    .map(augment, num_parallel_calls=tf.data.AUTOTUNE)\n    .batch(batch_size)\n    .prefetch(tf.data.AUTOTUNE)\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T09:38:38.170483Z","iopub.execute_input":"2025-02-27T09:38:38.170797Z","iopub.status.idle":"2025-02-27T09:38:38.619340Z","shell.execute_reply.started":"2025-02-27T09:38:38.170773Z","shell.execute_reply":"2025-02-27T09:38:38.618380Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"val_ds = (\n    val_ds\n    .map(load_resize_and_rescale, num_parallel_calls=tf.data.AUTOTUNE)\n    .batch(batch_size)\n    .prefetch(tf.data.AUTOTUNE)\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T09:38:40.619777Z","iopub.execute_input":"2025-02-27T09:38:40.620213Z","iopub.status.idle":"2025-02-27T09:38:40.645178Z","shell.execute_reply.started":"2025-02-27T09:38:40.620178Z","shell.execute_reply":"2025-02-27T09:38:40.644302Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"pretrained_base = ResNet152(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\navg = keras.layers.GlobalAveragePooling2D()(pretrained_base.output)\noutput = keras.layers.Dense(2, activation=\"softmax\")(avg)\nmodel = keras.models.Model(inputs=pretrained_base.input, outputs=output)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T14:19:11.819249Z","iopub.status.idle":"2025-02-26T14:19:11.819508Z","shell.execute_reply":"2025-02-26T14:19:11.819407Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for layer in pretrained_base.layers:\n    layer.trainable = False\n\nmodel.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\",\n              metrics=[\"accuracy\"])\nhistory = model.fit(train_ds,\n                    steps_per_epoch=int(0.75 * len(train_ds) / batch_size),\n                    validation_data=val_ds,\n                    validation_steps=int(0.15 * len(train_ds) / batch_size),\n                    epochs=5, \n                    verbose=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T14:19:11.820363Z","iopub.status.idle":"2025-02-26T14:19:11.820647Z","shell.execute_reply":"2025-02-26T14:19:11.820532Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for layer in pretrained_base.layers:\n    layer.trainable = True\n\nmodel.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\",\n              metrics=[\"accuracy\"])\nhistory = model.fit(train_ds,\n                    steps_per_epoch=int(0.75 * len(train_ds) / batch_size),\n                    validation_data=val_ds,\n                    validation_steps=int(0.15 * len(train_ds) / batch_size),\n                    epochs=5, \n                    verbose=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T14:19:11.821436Z","iopub.status.idle":"2025-02-26T14:19:11.821676Z","shell.execute_reply":"2025-02-26T14:19:11.821576Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"history_frame = pd.DataFrame(history.history)\nhistory_frame.loc[:, ['loss', 'val_loss']].plot()\nhistory_frame.loc[:, ['accuracy', 'val_accuracy']].plot();","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T14:19:11.825746Z","iopub.status.idle":"2025-02-26T14:19:11.825986Z","shell.execute_reply":"2025-02-26T14:19:11.825887Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_data = tf.data.Dataset.from_tensor_slices(test_full_path)\ntest_data = test_data.map(load_preprocess_image_1, num_parallel_calls=tf.data.AUTOTUNE)\ntest_data = test_data.batch(batch_size)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T14:19:11.826606Z","iopub.status.idle":"2025-02-26T14:19:11.826836Z","shell.execute_reply":"2025-02-26T14:19:11.826744Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pred = model.predict(test_data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T14:19:11.827540Z","iopub.status.idle":"2025-02-26T14:19:11.827838Z","shell.execute_reply":"2025-02-26T14:19:11.827676Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ar = [0 if i > 0.5 else 1 for i,j in pred]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T14:19:11.828530Z","iopub.status.idle":"2025-02-26T14:19:11.828842Z","shell.execute_reply":"2025-02-26T14:19:11.828733Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test[\"label\"] = ar\ntest.to_csv(\"predictions.csv\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T14:19:11.829399Z","iopub.status.idle":"2025-02-26T14:19:11.829678Z","shell.execute_reply":"2025-02-26T14:19:11.829569Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}