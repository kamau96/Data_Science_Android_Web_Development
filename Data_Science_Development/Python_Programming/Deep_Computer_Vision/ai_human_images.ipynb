{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10550636,"sourceType":"datasetVersion","datasetId":6412205}],"dockerImageVersionId":30886,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Detect AI vs Human generated images\nIn this notebook, I aim to build a convnet architecture for detecting real images from fake ones.","metadata":{}},{"cell_type":"code","source":"# Libraries used in this notebook\nimport kagglehub\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras.applications.resnet50 import ResNet50\nfrom keras.applications.resnet50 import preprocess_input, decode_predictions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T13:21:39.013480Z","iopub.execute_input":"2025-02-19T13:21:39.013848Z","iopub.status.idle":"2025-02-19T13:21:56.671793Z","shell.execute_reply.started":"2025-02-19T13:21:39.013815Z","shell.execute_reply":"2025-02-19T13:21:56.670317Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# Download latest version\ndata_path = kagglehub.dataset_download(\"alessandrasala79/ai-vs-human-generated-dataset\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T13:21:56.673600Z","iopub.execute_input":"2025-02-19T13:21:56.674417Z","iopub.status.idle":"2025-02-19T13:21:57.525134Z","shell.execute_reply.started":"2025-02-19T13:21:56.674378Z","shell.execute_reply":"2025-02-19T13:21:57.524121Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Csv with references to the images\ntrain_data = pd.read_csv(data_path + \"/\" + \"train.csv\", index_col=0)\ntest_data = pd.read_csv(data_path + \"/\" + \"test.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T13:21:57.527113Z","iopub.execute_input":"2025-02-19T13:21:57.527466Z","iopub.status.idle":"2025-02-19T13:21:57.727281Z","shell.execute_reply.started":"2025-02-19T13:21:57.527435Z","shell.execute_reply":"2025-02-19T13:21:57.726301Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"train_data.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T13:21:57.728374Z","iopub.execute_input":"2025-02-19T13:21:57.728708Z","iopub.status.idle":"2025-02-19T13:21:57.749537Z","shell.execute_reply.started":"2025-02-19T13:21:57.728680Z","shell.execute_reply":"2025-02-19T13:21:57.748549Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                         file_name  label\n0  train_data/a6dcb93f596a43249135678dfcfc17ea.jpg      1\n1  train_data/041be3153810433ab146bc97d5af505c.jpg      0\n2  train_data/615df26ce9494e5db2f70e57ce7a3a4f.jpg      1\n3  train_data/8542fe161d9147be8e835e50c0de39cd.jpg      0\n4  train_data/5d81fa12bc3b4cea8c94a6700a477cf2.jpg      1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>file_name</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>train_data/a6dcb93f596a43249135678dfcfc17ea.jpg</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>train_data/041be3153810433ab146bc97d5af505c.jpg</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>train_data/615df26ce9494e5db2f70e57ce7a3a4f.jpg</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>train_data/8542fe161d9147be8e835e50c0de39cd.jpg</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>train_data/5d81fa12bc3b4cea8c94a6700a477cf2.jpg</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"# Creates a specific paths to each image\ntrain_full_path = train_data[\"file_name\"].apply(lambda image_path: data_path + \"/\" + image_path).values\ntest_full_path = test_data[\"id\"].apply(lambda image_path: data_path + \"/\" + image_path).values\n\n# Labels for training data\ntrain_labels = train_data.loc[:,[\"label\"]]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T13:23:11.898608Z","iopub.execute_input":"2025-02-19T13:23:11.898947Z","iopub.status.idle":"2025-02-19T13:23:11.944731Z","shell.execute_reply.started":"2025-02-19T13:23:11.898921Z","shell.execute_reply":"2025-02-19T13:23:11.943259Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"train_dataset.take(1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T13:27:10.843062Z","iopub.execute_input":"2025-02-19T13:27:10.843481Z","iopub.status.idle":"2025-02-19T13:27:10.852751Z","shell.execute_reply.started":"2025-02-19T13:27:10.843447Z","shell.execute_reply":"2025-02-19T13:27:10.851089Z"}},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"<_TakeDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 1), dtype=tf.int64, name=None))>"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"# Function to load and preprocess an image\ndef load_and_preprocess_image(path, label):\n    image = tf.io.read_file(path)\n    image = tf.image.decode_jpeg(image, channels=3)  # Ensure RGB format\n    image = tf.image.resize(image, [224, 224])  # Resize to ResNet50 input size\n    image = preprocess_input(image)  # Apply ResNet50 preprocessing\n    return image, label\n\n# Create a TensorFlow dataset from image paths\ntrain_dataset = tf.data.Dataset.from_tensor_slices((train_full_path, train_labels))\ntest_dataset = tf.data.Dataset.from_tensor_slices((test_full_path, None))\n\n# Map the dataset to load and preprocess images\ntrain_dataset = train_dataset.map(load_and_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\ntest_dataset = test_dataset.map(load_and_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n\n# Batch the dataset (optional)\nbatch_size = 32\ntrain_dataset = train_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\ntest_dataset = test_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n\n# Example: Iterate over the dataset\nfor batch in train_dataset.take(1):  # Get first batch\n    print(batch.shape)  # Should be (batch_size, 224, 224, 3)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T13:25:01.241623Z","iopub.execute_input":"2025-02-19T13:25:01.241959Z","iopub.status.idle":"2025-02-19T13:25:01.554822Z","shell.execute_reply.started":"2025-02-19T13:25:01.241933Z","shell.execute_reply":"2025-02-19T13:25:01.553318Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-ff5d392b8108>\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Example: Iterate over the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Get first batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Should be (batch_size, 224, 224, 3)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'shape'"],"ename":"AttributeError","evalue":"'tuple' object has no attribute 'shape'","output_type":"error"}],"execution_count":14},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}