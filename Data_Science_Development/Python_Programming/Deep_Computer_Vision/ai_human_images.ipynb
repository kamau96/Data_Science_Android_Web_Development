{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10550636,"sourceType":"datasetVersion","datasetId":6412205}],"dockerImageVersionId":30886,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Detect AI vs Human generated images\nIn this notebook, I aim to build a convnet architecture for detecting real images from fake ones.","metadata":{}},{"cell_type":"code","source":"# Libraries used in this notebook\nimport kagglehub\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras.applications.resnet50 import ResNet50\nfrom keras.applications.resnet50 import preprocess_input, decode_predictions\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D\nfrom tensorflow.keras.models import Model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T10:43:13.175965Z","iopub.execute_input":"2025-02-20T10:43:13.176295Z","iopub.status.idle":"2025-02-20T10:43:34.409274Z","shell.execute_reply.started":"2025-02-20T10:43:13.176267Z","shell.execute_reply":"2025-02-20T10:43:34.408147Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# Download latest version\ndata_path = kagglehub.dataset_download(\"alessandrasala79/ai-vs-human-generated-dataset\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T09:04:22.547877Z","iopub.execute_input":"2025-02-20T09:04:22.548243Z","iopub.status.idle":"2025-02-20T09:04:22.907181Z","shell.execute_reply.started":"2025-02-20T09:04:22.548217Z","shell.execute_reply":"2025-02-20T09:04:22.906066Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# Csv with references to the images\ntrain_data = pd.read_csv(data_path + \"/\" + \"train.csv\", index_col=0)\ntest_data = pd.read_csv(data_path + \"/\" + \"test.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T09:04:22.908673Z","iopub.execute_input":"2025-02-20T09:04:22.908995Z","iopub.status.idle":"2025-02-20T09:04:23.025350Z","shell.execute_reply.started":"2025-02-20T09:04:22.908966Z","shell.execute_reply":"2025-02-20T09:04:23.024438Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"train_data.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T09:04:23.027451Z","iopub.execute_input":"2025-02-20T09:04:23.027753Z","iopub.status.idle":"2025-02-20T09:04:23.037403Z","shell.execute_reply.started":"2025-02-20T09:04:23.027729Z","shell.execute_reply":"2025-02-20T09:04:23.036423Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"                                         file_name  label\n0  train_data/a6dcb93f596a43249135678dfcfc17ea.jpg      1\n1  train_data/041be3153810433ab146bc97d5af505c.jpg      0\n2  train_data/615df26ce9494e5db2f70e57ce7a3a4f.jpg      1\n3  train_data/8542fe161d9147be8e835e50c0de39cd.jpg      0\n4  train_data/5d81fa12bc3b4cea8c94a6700a477cf2.jpg      1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>file_name</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>train_data/a6dcb93f596a43249135678dfcfc17ea.jpg</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>train_data/041be3153810433ab146bc97d5af505c.jpg</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>train_data/615df26ce9494e5db2f70e57ce7a3a4f.jpg</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>train_data/8542fe161d9147be8e835e50c0de39cd.jpg</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>train_data/5d81fa12bc3b4cea8c94a6700a477cf2.jpg</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"# Creates a specific paths to each image\ntrain_full_path = train_data[\"file_name\"].apply(lambda image_path: data_path + \"/\" + image_path).values\ntest_full_path = test_data[\"id\"].apply(lambda image_path: data_path + \"/\" + image_path).values\n\n# Labels for training data\ntrain_labels = train_data.loc[:,\"label\"].values","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T09:04:23.038660Z","iopub.execute_input":"2025-02-20T09:04:23.038926Z","iopub.status.idle":"2025-02-20T09:04:23.094465Z","shell.execute_reply.started":"2025-02-20T09:04:23.038904Z","shell.execute_reply":"2025-02-20T09:04:23.093364Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# Function to load and preprocess an image\ndef load_and_preprocess_image(path, label=None):\n    image = tf.io.read_file(path)\n    image = tf.image.decode_jpeg(image, channels=3)  # Ensure RGB format\n    image = tf.image.resize(image, [224, 224])  # Resize to ResNet50 input size\n    image = preprocess_input(image)  # Apply ResNet50 preprocessing\n    return image, label\n\n# Create a TensorFlow dataset from image paths\ntrain_dataset = tf.data.Dataset.from_tensor_slices((train_full_path, train_labels))\ntest_dataset = tf.data.Dataset.from_tensor_slices((test_full_path))\n\n# Shuffle train dataset\nbuffer_size = len(train_dataset)  # Set buffer size to dataset size for perfect shuffling\ntrain_dataset = train_dataset.shuffle(buffer_size, reshuffle_each_iteration=True)\n\n# Map the dataset to load and preprocess images\ntrain_dataset = train_dataset.map(load_and_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\ntest_dataset = test_dataset.map(load_and_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n\n# Batch the dataset (optional)\nbatch_size = 32\ntrain_dataset = train_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\ntest_dataset = test_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T09:04:23.095514Z","iopub.execute_input":"2025-02-20T09:04:23.095793Z","iopub.status.idle":"2025-02-20T09:04:23.222931Z","shell.execute_reply.started":"2025-02-20T09:04:23.095771Z","shell.execute_reply":"2025-02-20T09:04:23.221809Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}