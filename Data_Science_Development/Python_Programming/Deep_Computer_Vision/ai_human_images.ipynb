{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10550636,"sourceType":"datasetVersion","datasetId":6412205}],"dockerImageVersionId":30886,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Detect AI vs Human generated images\nIn this notebook, I aim to build a convnet architecture for detecting real images from fake ones.","metadata":{}},{"cell_type":"code","source":"# Libraries used in this notebook\nimport kagglehub\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras.applications.resnet50 import ResNet50\nfrom keras.applications.resnet50 import preprocess_input, decode_predictions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T14:50:35.897767Z","iopub.execute_input":"2025-02-19T14:50:35.898126Z","iopub.status.idle":"2025-02-19T14:50:54.540781Z","shell.execute_reply.started":"2025-02-19T14:50:35.898100Z","shell.execute_reply":"2025-02-19T14:50:54.539916Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# Download latest version\ndata_path = kagglehub.dataset_download(\"alessandrasala79/ai-vs-human-generated-dataset\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T14:50:54.542118Z","iopub.execute_input":"2025-02-19T14:50:54.542822Z","iopub.status.idle":"2025-02-19T14:50:54.750534Z","shell.execute_reply.started":"2025-02-19T14:50:54.542783Z","shell.execute_reply":"2025-02-19T14:50:54.749445Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Csv with references to the images\ntrain_data = pd.read_csv(data_path + \"/\" + \"train.csv\", index_col=0)\ntest_data = pd.read_csv(data_path + \"/\" + \"test.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T14:50:54.752265Z","iopub.execute_input":"2025-02-19T14:50:54.752692Z","iopub.status.idle":"2025-02-19T14:50:54.932183Z","shell.execute_reply.started":"2025-02-19T14:50:54.752649Z","shell.execute_reply":"2025-02-19T14:50:54.931367Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"train_data.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T14:50:54.933405Z","iopub.execute_input":"2025-02-19T14:50:54.933738Z","iopub.status.idle":"2025-02-19T14:50:54.957125Z","shell.execute_reply.started":"2025-02-19T14:50:54.933712Z","shell.execute_reply":"2025-02-19T14:50:54.956026Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                         file_name  label\n0  train_data/a6dcb93f596a43249135678dfcfc17ea.jpg      1\n1  train_data/041be3153810433ab146bc97d5af505c.jpg      0\n2  train_data/615df26ce9494e5db2f70e57ce7a3a4f.jpg      1\n3  train_data/8542fe161d9147be8e835e50c0de39cd.jpg      0\n4  train_data/5d81fa12bc3b4cea8c94a6700a477cf2.jpg      1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>file_name</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>train_data/a6dcb93f596a43249135678dfcfc17ea.jpg</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>train_data/041be3153810433ab146bc97d5af505c.jpg</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>train_data/615df26ce9494e5db2f70e57ce7a3a4f.jpg</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>train_data/8542fe161d9147be8e835e50c0de39cd.jpg</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>train_data/5d81fa12bc3b4cea8c94a6700a477cf2.jpg</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"# Creates a specific paths to each image\ntrain_full_path = train_data[\"file_name\"].apply(lambda image_path: data_path + \"/\" + image_path).values\ntest_full_path = test_data[\"id\"].apply(lambda image_path: data_path + \"/\" + image_path).values\n\n# Labels for training data\ntrain_labels = train_data.loc[:,\"label\"].values","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T14:50:54.958153Z","iopub.execute_input":"2025-02-19T14:50:54.958483Z","iopub.status.idle":"2025-02-19T14:50:55.002521Z","shell.execute_reply.started":"2025-02-19T14:50:54.958456Z","shell.execute_reply":"2025-02-19T14:50:55.001417Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Function to load and preprocess an image\ndef load_and_preprocess_image(path, label=None):\n    image = tf.io.read_file(path)\n    image = tf.image.decode_jpeg(image, channels=3)  # Ensure RGB format\n    image = tf.image.resize(image, [224, 224])  # Resize to ResNet50 input size\n    image = preprocess_input(image)  # Apply ResNet50 preprocessing\n    return image, label\n\n# Create a TensorFlow dataset from image paths\ntrain_dataset = tf.data.Dataset.from_tensor_slices((train_full_path, train_labels))\ntest_dataset = tf.data.Dataset.from_tensor_slices((test_full_path))\n\n# Shuffle train dataset\nbuffer_size = len(train_dataset)  # Set buffer size to dataset size for perfect shuffling\ntrain_dataset = train_dataset.shuffle(buffer_size, reshuffle_each_iteration=True)\n\n# Map the dataset to load and preprocess images\ntrain_dataset = train_dataset.map(load_and_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\ntest_dataset = test_dataset.map(load_and_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n\n# Batch the dataset (optional)\nbatch_size = 32\ntrain_dataset = train_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\ntest_dataset = test_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T14:50:55.003538Z","iopub.execute_input":"2025-02-19T14:50:55.003919Z","iopub.status.idle":"2025-02-19T14:50:55.558848Z","shell.execute_reply.started":"2025-02-19T14:50:55.003871Z","shell.execute_reply":"2025-02-19T14:50:55.557991Z"}},"outputs":[{"name":"stdout","text":"(32, 224, 224, 3)\n(32,)\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}