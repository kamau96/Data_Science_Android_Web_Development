{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10550636,"sourceType":"datasetVersion","datasetId":6412205}],"dockerImageVersionId":30886,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Detect AI vs Human generated images\nIn this notebook, I aim to build a convnet architecture for detecting real images from fake ones.","metadata":{}},{"cell_type":"code","source":"# Libraries used in this notebook\nimport kagglehub\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras.applications.resnet50 import ResNet50\nfrom tensorflow.keras.applications import Xception\nfrom keras.applications.resnet50 import preprocess_input, decode_predictions\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D\nfrom tensorflow.keras.models import Model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T15:35:50.323713Z","iopub.execute_input":"2025-02-20T15:35:50.324034Z","iopub.status.idle":"2025-02-20T15:36:05.718545Z","shell.execute_reply.started":"2025-02-20T15:35:50.324001Z","shell.execute_reply":"2025-02-20T15:36:05.717346Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# Download latest version\ndata_path = kagglehub.dataset_download(\"alessandrasala79/ai-vs-human-generated-dataset\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T15:36:05.720077Z","iopub.execute_input":"2025-02-20T15:36:05.720726Z","iopub.status.idle":"2025-02-20T15:36:05.843198Z","shell.execute_reply.started":"2025-02-20T15:36:05.720698Z","shell.execute_reply":"2025-02-20T15:36:05.842265Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Csv with references to the images\ntrain_data = pd.read_csv(data_path + \"/\" + \"train.csv\", index_col=0)\ntest_data = pd.read_csv(data_path + \"/\" + \"test.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T15:36:05.844990Z","iopub.execute_input":"2025-02-20T15:36:05.845285Z","iopub.status.idle":"2025-02-20T15:36:05.998641Z","shell.execute_reply.started":"2025-02-20T15:36:05.845264Z","shell.execute_reply":"2025-02-20T15:36:05.997755Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"train_data.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T15:36:05.999943Z","iopub.execute_input":"2025-02-20T15:36:06.000271Z","iopub.status.idle":"2025-02-20T15:36:06.017870Z","shell.execute_reply.started":"2025-02-20T15:36:06.000242Z","shell.execute_reply":"2025-02-20T15:36:06.017002Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                         file_name  label\n0  train_data/a6dcb93f596a43249135678dfcfc17ea.jpg      1\n1  train_data/041be3153810433ab146bc97d5af505c.jpg      0\n2  train_data/615df26ce9494e5db2f70e57ce7a3a4f.jpg      1\n3  train_data/8542fe161d9147be8e835e50c0de39cd.jpg      0\n4  train_data/5d81fa12bc3b4cea8c94a6700a477cf2.jpg      1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>file_name</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>train_data/a6dcb93f596a43249135678dfcfc17ea.jpg</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>train_data/041be3153810433ab146bc97d5af505c.jpg</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>train_data/615df26ce9494e5db2f70e57ce7a3a4f.jpg</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>train_data/8542fe161d9147be8e835e50c0de39cd.jpg</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>train_data/5d81fa12bc3b4cea8c94a6700a477cf2.jpg</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"# Creates a specific paths to each image\ntrain_full_path = train_data[\"file_name\"].apply(lambda image_path: data_path + \"/\" + image_path).values\ntest_full_path = test_data[\"id\"].apply(lambda image_path: data_path + \"/\" + image_path).values\n\n# Labels for training data\ntrain_labels = train_data.loc[:,\"label\"].values","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T15:36:06.018731Z","iopub.execute_input":"2025-02-20T15:36:06.019014Z","iopub.status.idle":"2025-02-20T15:36:06.053556Z","shell.execute_reply.started":"2025-02-20T15:36:06.018980Z","shell.execute_reply":"2025-02-20T15:36:06.052999Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Function to load and preprocess an image\ndef load_and_preprocess_image(path, label=None):\n    image = tf.io.read_file(path)\n    image = tf.image.decode_jpeg(image, channels=3)  # Ensure RGB format\n    image = tf.image.resize(image, [224, 224])  # Resize to ResNet50 input size\n    image = preprocess_input(image)  # Apply ResNet50 preprocessing\n    return image, label\n\n# Create a TensorFlow dataset from image paths\ntrain_dataset = tf.data.Dataset.from_tensor_slices((train_full_path, train_labels))\ntest_dataset = tf.data.Dataset.from_tensor_slices((test_full_path))\n\n# Shuffle train dataset\nbuffer_size = len(train_dataset)  # Set buffer size to dataset size for perfect shuffling\ntrain_dataset = train_dataset.shuffle(buffer_size, reshuffle_each_iteration=True)\n\n# Map the dataset to load and preprocess images\ntrain_dataset = train_dataset.map(load_and_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\ntest_dataset = test_dataset.map(load_and_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n\n# Batch the dataset (optional)\nbatch_size = 32\ntrain_dataset = train_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\ntest_dataset = test_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T15:36:06.054212Z","iopub.execute_input":"2025-02-20T15:36:06.054398Z","iopub.status.idle":"2025-02-20T15:36:07.485141Z","shell.execute_reply.started":"2025-02-20T15:36:06.054381Z","shell.execute_reply":"2025-02-20T15:36:07.484487Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"base_model = keras.applications.resnet50.ResNet50(weights=\"imagenet\", include_top=False)\navg = keras.layers.GlobalAveragePooling2D()(base_model.output)\noutput = keras.layers.Dense(2, activation=\"softmax\")(avg)\nmodel = keras.Model(inputs=base_model.input, outputs=output)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T15:36:07.522118Z","iopub.execute_input":"2025-02-20T15:36:07.522398Z","iopub.status.idle":"2025-02-20T15:36:11.010364Z","shell.execute_reply.started":"2025-02-20T15:36:07.522377Z","shell.execute_reply":"2025-02-20T15:36:11.009425Z"}},"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"for layer in base_model.layers:\n    layer.trainable = False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T15:36:11.011280Z","iopub.execute_input":"2025-02-20T15:36:11.011577Z","iopub.status.idle":"2025-02-20T15:36:11.017257Z","shell.execute_reply.started":"2025-02-20T15:36:11.011549Z","shell.execute_reply":"2025-02-20T15:36:11.016580Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"lr_schedule = keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=0.2, \n                                                          decay_steps=10000, \n                                                          decay_rate=0.96, \n                                                          staircase=True)\n\noptimizer = keras.optimizers.SGD(learning_rate=lr_schedule, momentum=0.9)\nmodel.compile(loss=\"sparse_categorical_crossentropy\",\n              optimizer=optimizer,\n              metrics=[\"accuracy\"])\nhistory = model.fit(train_dataset, epochs=10)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T15:36:11.018087Z","iopub.execute_input":"2025-02-20T15:36:11.018364Z","iopub.status.idle":"2025-02-20T16:13:51.149876Z","shell.execute_reply.started":"2025-02-20T15:36:11.018335Z","shell.execute_reply":"2025-02-20T16:13:51.149196Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10\n\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m249s\u001b[0m 95ms/step - accuracy: 0.9175 - loss: 6.6115\nEpoch 2/10\n\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 90ms/step - accuracy: 0.9523 - loss: 4.6990\nEpoch 3/10\n\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 89ms/step - accuracy: 0.9576 - loss: 4.1168\nEpoch 4/10\n\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 89ms/step - accuracy: 0.9563 - loss: 4.3551\nEpoch 5/10\n\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 89ms/step - accuracy: 0.9608 - loss: 4.2822\nEpoch 6/10\n\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 89ms/step - accuracy: 0.9625 - loss: 3.9525\nEpoch 7/10\n\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 89ms/step - accuracy: 0.9628 - loss: 3.6003\nEpoch 8/10\n\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 89ms/step - accuracy: 0.9604 - loss: 4.1451\nEpoch 9/10\n\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 89ms/step - accuracy: 0.9636 - loss: 3.7494\nEpoch 10/10\n\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 89ms/step - accuracy: 0.9647 - loss: 3.4793\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"lr_schedule = keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=0.01, \n                                                          decay_steps=10000, \n                                                          decay_rate=0.96, \n                                                          staircase=True)\nfor layer in base_model.layers:\n    layer.trainable = True\noptimizer = keras.optimizers.SGD(learning_rate=lr_schedule, momentum=0.9)\nmodel.compile(loss=\"sparse_categorical_crossentropy\",\n              optimizer=optimizer,\n              metrics=[\"accuracy\"])\nhistory = model.fit(train_dataset, epochs=10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T16:13:51.151009Z","iopub.execute_input":"2025-02-20T16:13:51.151372Z","iopub.status.idle":"2025-02-20T18:17:50.253898Z","shell.execute_reply.started":"2025-02-20T16:13:51.151338Z","shell.execute_reply":"2025-02-20T18:17:50.253223Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10\n\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m793s\u001b[0m 302ms/step - accuracy: 0.7154 - loss: 17.7092\nEpoch 2/10\n\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m738s\u001b[0m 295ms/step - accuracy: 0.8271 - loss: 1.5609\nEpoch 3/10\n\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m739s\u001b[0m 295ms/step - accuracy: 0.8433 - loss: 0.9423\nEpoch 4/10\n\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m738s\u001b[0m 295ms/step - accuracy: 0.8307 - loss: 0.9563\nEpoch 5/10\n\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m740s\u001b[0m 296ms/step - accuracy: 0.8357 - loss: 1.6537\nEpoch 6/10\n\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m737s\u001b[0m 295ms/step - accuracy: 0.8460 - loss: 1.0599\nEpoch 7/10\n\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m735s\u001b[0m 294ms/step - accuracy: 0.8476 - loss: 0.6713\nEpoch 8/10\n\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m739s\u001b[0m 296ms/step - accuracy: 0.8554 - loss: 0.6088\nEpoch 9/10\n\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m740s\u001b[0m 296ms/step - accuracy: 0.8586 - loss: 0.6294\nEpoch 10/10\n\u001b[1m2499/2499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m739s\u001b[0m 296ms/step - accuracy: 0.8598 - loss: 0.5765\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"predictions = model.predict(test_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T18:18:15.248299Z","iopub.execute_input":"2025-02-20T18:18:15.248631Z","iopub.status.idle":"2025-02-20T18:19:17.186969Z","shell.execute_reply.started":"2025-02-20T18:18:15.248601Z","shell.execute_reply":"2025-02-20T18:19:17.186310Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 337ms/step\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"class_labels = (predictions > 0.5).astype(int)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T18:25:30.429634Z","iopub.execute_input":"2025-02-20T18:25:30.429961Z","iopub.status.idle":"2025-02-20T18:25:30.434132Z","shell.execute_reply.started":"2025-02-20T18:25:30.429933Z","shell.execute_reply":"2025-02-20T18:25:30.433150Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"ar = []\nfor i in predictions:\n    if i[0] > i[1]:\n        ar.append(1)\n    else:\n        ar.append(0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T18:38:48.754155Z","iopub.execute_input":"2025-02-20T18:38:48.754584Z","iopub.status.idle":"2025-02-20T18:38:48.764584Z","shell.execute_reply.started":"2025-02-20T18:38:48.754544Z","shell.execute_reply":"2025-02-20T18:38:48.763591Z"}},"outputs":[],"execution_count":49},{"cell_type":"code","source":"test_data[\"label\"] = ar","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T18:38:50.770035Z","iopub.execute_input":"2025-02-20T18:38:50.770375Z","iopub.status.idle":"2025-02-20T18:38:50.775836Z","shell.execute_reply.started":"2025-02-20T18:38:50.770348Z","shell.execute_reply":"2025-02-20T18:38:50.775078Z"}},"outputs":[],"execution_count":50},{"cell_type":"code","source":"test_data.to_csv(\"predictions.csv\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T18:38:55.841462Z","iopub.execute_input":"2025-02-20T18:38:55.841739Z","iopub.status.idle":"2025-02-20T18:38:55.855211Z","shell.execute_reply.started":"2025-02-20T18:38:55.841717Z","shell.execute_reply":"2025-02-20T18:38:55.854494Z"}},"outputs":[],"execution_count":51},{"cell_type":"code","source":"model.save(\"/kaggle/working/ai-vs-human-images.h5\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T18:46:53.110468Z","iopub.execute_input":"2025-02-20T18:46:53.110771Z","iopub.status.idle":"2025-02-20T18:46:53.758797Z","shell.execute_reply.started":"2025-02-20T18:46:53.110747Z","shell.execute_reply":"2025-02-20T18:46:53.758142Z"}},"outputs":[],"execution_count":53},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}