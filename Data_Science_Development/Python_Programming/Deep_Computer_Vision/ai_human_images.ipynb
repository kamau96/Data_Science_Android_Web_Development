{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10550636,"sourceType":"datasetVersion","datasetId":6412205}],"dockerImageVersionId":30886,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Detect AI vs Human generated images\nIn this notebook, I aim to build a convnet architecture for detecting real images from fake ones.","metadata":{}},{"cell_type":"code","source":"# All imports needed for this classification project\nimport kagglehub\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.applications.resnet50 import preprocess_input\nfrom tensorflow.keras.regularizers import l2","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Download latest version\ndata_path = kagglehub.dataset_download(\"alessandrasala79/ai-vs-human-generated-dataset\")\n\nprint(\"Path to dataset files:\", data_path)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Csv files with paths to the images\ntrain = pd.read_csv(data_path+\"/\"+\"train.csv\", index_col=0)\ntest = pd.read_csv(data_path+\"/\"+\"test.csv\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(train.head())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def create_image_fullpath(file_path, labels=None):\n    \"\"\"\n    Creates an array with full path to the images.\n    Labels array created where appropriate.\n    \"\"\"\n    full_path = [data_path +\"/\"+ image_path for image_path in file_path]\n    full_path = np.array(full_path)\n    if labels is not None:\n        labels = np.array(labels)\n        return full_path, labels\n    else:\n        return full_path","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Creates full paths to images\ntrain_full_path, labels = create_image_fullpath(train[\"file_name\"], train[\"label\"])\ntest_full_path = create_image_fullpath(test[\"id\"])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Visualize the the first ten images. \nfig, ax = plt.subplots(5, 2, figsize=(10,10))\n\nindex = 0\nfor i in range(5):\n    for j in range(2):\n        im = plt.imread(train_full_path[index])\n        ax[i][j].imshow(im)\n        ax[i][j].axis(\"off\")\n        \n        if labels[index] == 0:\n            ax[i][j].set_title(\"Human generated\")\n        else:\n            ax[i][j].set_title(\"AI generated\")\n            \n        index += 1\n\n                  \nfig.tight_layout()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Based on the above visualizations, it's evidented the data isn't shuffled and image sizes are different.","metadata":{}},{"cell_type":"code","source":"# Shuffle train data\nindices = np.random.permutation(len(train_full_path))\ntrain_full_path, labels = train_full_path[indices], labels[indices]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Split train into train and validation data\nX_train, X_val, y_train, y_val = train_test_split(train_full_path, \n                                                  labels,\n                                                  test_size=0.2,\n                                                  random_state=44)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def load_preprocess_image(X, y=None):\n    image = tf.io.read_file(X)\n    image = tf.image.decode_jpeg(image, channels=3)/255\n    image_resized = tf.image.resize(image, [224, 224])\n    image_resized = preprocess_input(image_resized*255)\n\n    if y is None:\n        return image_resized\n    else:\n        return image_resized, y\n    ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# I'll convert the numpy arrays to tensorflow dataset\n\ntrain_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train))\nval_ds = tf.data.Dataset.from_tensor_slices((X_val, y_val))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Apply the data processing on the tf dataset\ntrain_ds = train_ds.map(load_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\nval_ds = val_ds.map(load_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n\n# Batch the dataset\nbatch_size = 32\ntrain_ds = train_ds.batch(batch_size)\nval_ds = val_ds.batch(batch_size)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pretrained_base = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\npretrained_base.trainable = False","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = keras.Sequential([\n    pretrained_base,\n    layers.GlobalAveragePooling2D(), \n    layers.Dense(128, activation='relu', kernel_regularizer=l2(0.01)),  \n    layers.Dropout(0.5), \n    layers.Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n    layers.Dropout(0.3), \n    layers.Dense(1, activation='sigmoid')  \n])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.compile(\n    optimizer='adam',\n    loss='binary_crossentropy',\n    metrics=['binary_accuracy'],\n)\n\nhistory = model.fit(\n    train_ds,\n    validation_data=val_ds,\n    epochs=5,\n    verbose=1,\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"history_frame = pd.DataFrame(history.history)\nhistory_frame.loc[:, ['loss', 'val_loss']].plot()\nhistory_frame.loc[:, ['binary_accuracy', 'val_binary_accuracy']].plot();","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_data = tf.data.Dataset.from_tensor_slices(test_full_path)\ntest_data = test_data.map(load_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\ntest_data = test_data.batch(batch_size)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pred = model.predict(test_data)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ar = [0 if i < 0.5 else 1 for i in pred]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test[\"label\"] = ar\ntest.to_csv(\"predictions.csv\", index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}