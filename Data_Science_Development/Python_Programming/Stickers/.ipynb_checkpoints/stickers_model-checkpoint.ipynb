{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a4d8d7a-4064-4fc2-8808-6c2e629c5394",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Libraries that I'll use throughout the notebook.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score, TimeSeriesSplit\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0190aba1-8e6a-47e3-a112-b3f62047912a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data used for time series analysis.\n",
    "path = \"../../../Data/playground-series-s5e1/\"\n",
    "train = pd.read_csv(path+\"train.csv\", \n",
    "                    index_col=[\"date\"], \n",
    "                    parse_dates=[\"date\"], \n",
    "                    usecols=[\"date\", \"country\", \"store\", \"product\", \"num_sold\"])\n",
    "test = pd.read_csv(path+\"test.csv\", \n",
    "                   index_col=[\"date\"],\n",
    "                   parse_dates=[\"date\"], \n",
    "                   usecols=[\"date\", \"country\", \"store\", \"product\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0a9a456-6fe8-44ba-9fa0-ca0e4934afe7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# For now filling mean the non-optimal way.\n",
    "num_sold_mean = np.mean(train[\"num_sold\"])\n",
    "train[\"num_sold\"] = train[\"num_sold\"].fillna(num_sold_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c022b7ed-a935-4381-9938-7bc2b2d67a96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This ensures that sales of a particular follow each other.\n",
    "train = train.sort_values(by=[\"country\",\"date\"])\n",
    "test = test.sort_values(by=[\"country\", \"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9058bd2-2abc-4953-a068-acdabf291e9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Adding the lag of the target variable from 6 steps back up to 24.\n",
    "for i in range(6, 25):\n",
    "    li = []\n",
    "    # Ensures that lag is performed per country.\n",
    "    for country in train[\"country\"].unique():\n",
    "        data = train[train[\"country\"]==country][\"num_sold\"].shift(i)\n",
    "        li.append(data.values)\n",
    "    arr = np.array(li)\n",
    "    train[f\"lag_{i}\"] = arr.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "077940ab-7f62-41f8-a496-80cd873e7493",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (230130, 14), indices imply (230130, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m one_hot \u001b[38;5;241m=\u001b[39m OneHotEncoder()\n\u001b[0;32m      2\u001b[0m cat_train \u001b[38;5;241m=\u001b[39m one_hot\u001b[38;5;241m.\u001b[39mfit_transform(train[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcountry\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstore\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproduct\u001b[39m\u001b[38;5;124m\"\u001b[39m]])\u001b[38;5;241m.\u001b[39mtoarray()\n\u001b[1;32m----> 3\u001b[0m cat_train \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(cat_train,  \n\u001b[0;32m      4\u001b[0m                          columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcountry\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstore\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproduct\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m      5\u001b[0m                          index\u001b[38;5;241m=\u001b[39mtrain\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:758\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    747\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(\n\u001b[0;32m    748\u001b[0m             \u001b[38;5;66;03m# error: Item \"ndarray\" of \"Union[ndarray, Series, Index]\" has no\u001b[39;00m\n\u001b[0;32m    749\u001b[0m             \u001b[38;5;66;03m# attribute \"name\"\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    755\u001b[0m             copy\u001b[38;5;241m=\u001b[39m_copy,\n\u001b[0;32m    756\u001b[0m         )\n\u001b[0;32m    757\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 758\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m ndarray_to_mgr(\n\u001b[0;32m    759\u001b[0m             data,\n\u001b[0;32m    760\u001b[0m             index,\n\u001b[0;32m    761\u001b[0m             columns,\n\u001b[0;32m    762\u001b[0m             dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m    763\u001b[0m             copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m    764\u001b[0m             typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[0;32m    765\u001b[0m         )\n\u001b[0;32m    767\u001b[0m \u001b[38;5;66;03m# For data is list-like, or Iterable (will consume into list)\u001b[39;00m\n\u001b[0;32m    768\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like(data):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:337\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[1;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;66;03m# _prep_ndarraylike ensures that values.ndim == 2 at this point\u001b[39;00m\n\u001b[0;32m    333\u001b[0m index, columns \u001b[38;5;241m=\u001b[39m _get_axes(\n\u001b[0;32m    334\u001b[0m     values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], index\u001b[38;5;241m=\u001b[39mindex, columns\u001b[38;5;241m=\u001b[39mcolumns\n\u001b[0;32m    335\u001b[0m )\n\u001b[1;32m--> 337\u001b[0m _check_values_indices_shape_match(values, index, columns)\n\u001b[0;32m    339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    340\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:408\u001b[0m, in \u001b[0;36m_check_values_indices_shape_match\u001b[1;34m(values, index, columns)\u001b[0m\n\u001b[0;32m    406\u001b[0m passed \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m    407\u001b[0m implied \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mlen\u001b[39m(index), \u001b[38;5;28mlen\u001b[39m(columns))\n\u001b[1;32m--> 408\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of passed values is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpassed\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, indices imply \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimplied\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Shape of passed values is (230130, 14), indices imply (230130, 3)"
     ]
    }
   ],
   "source": [
    "one_hot = OneHotEncoder()\n",
    "cat_train = one_hot.fit_transform(train[[\"country\", \"store\", \"product\"]]).toarray()\n",
    "cat_train = pd.DataFrame(cat_train, \n",
    "                         columns=[\"country_1\", \"country_2\", \"country_3\", \n",
    "                                  \"country_4\", \"country_5\", \"country_6\", \n",
    "                                  \"store_1\", \"store_2\", \"store_3\", \n",
    "                                  \"product_1\", \"product_2\", \"product_3\", \n",
    "                                  \"product_4\", \"product_5\"], \n",
    "                         index=train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0373a9b1-80e6-4c21-808a-455c713fa3ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train.drop([\"country\", \"store\", \"product\"], axis=1, inplace=True)\n",
    "train = pd.concat([train, cat_train], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3f926f-2a32-4909-a711-d1f8b557801f",
   "metadata": {},
   "source": [
    "Great, we have generated a dataset here. Why don't we now train a model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea16663-738c-4dd3-9e53-e40e6b12d8b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for time-series cross-validation set 5 folds \n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "def timeseries_train_test_split(X, y, test_size):\n",
    "    \"\"\"\n",
    "        Perform train-test split with respect to time series structure\n",
    "    \"\"\"\n",
    "    \n",
    "    # get the index after which test set starts\n",
    "    test_index = int(len(X)*(1-test_size))\n",
    "    \n",
    "    X_train = X.iloc[:test_index]\n",
    "    y_train = y.iloc[:test_index]\n",
    "    X_test = X.iloc[test_index:]\n",
    "    y_test = y.iloc[test_index:]\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "y = train.dropna().num_sold\n",
    "X = train.dropna().drop([\"num_sold\"], axis=1)\n",
    "\n",
    "# reserve 30% of data for testing\n",
    "X_train, X_test, y_train, y_test = timeseries_train_test_split(X, y, test_size=0.3)\n",
    "# machine learning in two lines\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb0805b-146c-4190-bd7e-c5abac754b9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "def plotModelResults(model, X_train=X_train, X_test=X_test, plot_intervals=False, plot_anomalies=False):\n",
    "    \"\"\"\n",
    "        Plots modelled vs fact values, prediction intervals and anomalies\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    prediction = model.predict(X_test)\n",
    "    \n",
    "    plt.figure(figsize=(15, 7))\n",
    "    plt.plot(prediction, \"g\", label=\"prediction\", linewidth=2.0)\n",
    "    plt.plot(y_test.values, label=\"actual\", linewidth=2.0)\n",
    "    \n",
    "    if plot_intervals:\n",
    "        cv = cross_val_score(model, X_train, y_train, \n",
    "                                    cv=tscv, \n",
    "                                    scoring=\"neg_mean_absolute_error\")\n",
    "        mae = cv.mean() * (-1)\n",
    "        deviation = cv.std()\n",
    "        \n",
    "        scale = 1.96\n",
    "        lower = prediction - (mae + scale * deviation)\n",
    "        upper = prediction + (mae + scale * deviation)\n",
    "        \n",
    "        plt.plot(lower, \"r--\", label=\"upper bond / lower bond\", alpha=0.5)\n",
    "        plt.plot(upper, \"r--\", alpha=0.5)\n",
    "        \n",
    "        if plot_anomalies:\n",
    "            anomalies = np.array([np.NaN]*len(y_test))\n",
    "            anomalies[y_test<lower] = y_test[y_test<lower]\n",
    "            anomalies[y_test>upper] = y_test[y_test>upper]\n",
    "            plt.plot(anomalies, \"o\", markersize=10, label = \"Anomalies\")\n",
    "    \n",
    "    error = mean_absolute_percentage_error(prediction, y_test)\n",
    "    plt.title(\"Mean absolute percentage error {0:.2f}%\".format(error))\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.tight_layout()\n",
    "    plt.grid(True);\n",
    "    \n",
    "def plotCoefficients(model):\n",
    "    \"\"\"\n",
    "        Plots sorted coefficient values of the model\n",
    "    \"\"\"\n",
    "    \n",
    "    coefs = pd.DataFrame(model.coef_, X_train.columns)\n",
    "    coefs.columns = [\"coef\"]\n",
    "    coefs[\"abs\"] = coefs.coef.apply(np.abs)\n",
    "    coefs = coefs.sort_values(by=\"abs\", ascending=False).drop([\"abs\"], axis=1)\n",
    "    \n",
    "    plt.figure(figsize=(15, 7))\n",
    "    coefs.coef.plot(kind='bar')\n",
    "    plt.grid(True, axis='y')\n",
    "    plt.hlines(y=0, xmin=0, xmax=len(coefs), linestyles='dashed');\n",
    "plotModelResults(lr, plot_intervals=True)\n",
    "plotCoefficients(lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0804b574-ccee-48bc-bcca-09178de19b3e",
   "metadata": {},
   "source": [
    "Simple lags and linear regression gave us predictions that are not that far off from SARIMA in terms of quality. There are many unnecessary features, so we'll do feature selection in a little while. For now, let's continue engineering!\n",
    "\n",
    "We'll add hour, day of week, and a boolean for is_weekend. To do so, we need to transform the current dataframe index into the datetime format and extract hour and weekday.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99468d77-078b-4482-a8f1-d7f293785405",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train.index = pd.to_datetime(train.index)\n",
    "train[\"hour\"] = train.index.hour\n",
    "train[\"weekday\"] = train.index.weekday\n",
    "train['is_weekend'] = train.weekday.isin([5,6])*1\n",
    "train.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48917543-5760-4023-8936-a4599febce71",
   "metadata": {
    "tags": []
   },
   "source": [
    "We can visualize the resulting features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a003d997-6a99-4229-aefd-80dbff491079",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 5))\n",
    "plt.title(\"Encoded features\")\n",
    "train.hour.plot()\n",
    "train.weekday.plot()\n",
    "train.is_weekend.plot()\n",
    "plt.grid(True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5fc82b1-9122-47a2-a7e3-c59db68a8b0f",
   "metadata": {},
   "source": [
    "Since we now have different scales in our variables, thousands for the lag features and tens for categorical, we need to transform them into same scale for exploring feature importance and, later, regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abdaa1f-8bbd-4ac8-9860-a722c4111a53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "y = train.dropna().num_sold\n",
    "X = train.dropna().drop([\"num_sold\"], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = timeseries_train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "plotModelResults(lr, X_train=X_train_scaled, X_test=X_test_scaled, plot_intervals=True)\n",
    "plotCoefficients(lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8d6af7-7a06-452b-8ba2-cc5471c718ca",
   "metadata": {},
   "source": [
    "The test error goes down a little bit. Judging by the coefficients plot, we can say that weekday and is_weekend are useful features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7bc7ee-c136-4ba6-80e1-005719a2d302",
   "metadata": {},
   "source": [
    "Target encoding\n",
    "I'd like to add another variant for encoding categorical variables: encoding by mean value. If it is undesirable to explode a dataset by using many dummy variables that can lead to the loss of information and if they cannot be used as real values because of the conflicts like \"0 hours < 23 hours\", then it's possible to encode a variable with slightly more interpretable values. The natural idea is to encode with the mean value of the target variable. In our example, every day of the week and every hour of the day can be encoded by the corresponding average number of ads watched during that day or hour. It's very important to make sure that the mean value is calculated over the training set only (or over the current cross-validation fold only) so that the model is not aware of the future.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111b97b2-138e-4667-83e1-0efc327210db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def code_mean(data, cat_feature, real_feature):\n",
    "    \"\"\"\n",
    "    Returns a dictionary where keys are unique categories of the cat_feature,\n",
    "    and values are means over real_feature\n",
    "    \"\"\"\n",
    "    return dict(data.groupby(cat_feature)[real_feature].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd51ea36-f632-48c2-b1fa-4b9f66a314ba",
   "metadata": {},
   "source": [
    "Let's look at the averages by hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94145bd1-6e62-47b8-95bf-f9206dd6ebc3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "average_hour = code_mean(train, \"hour\", \"num_sold\")\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.title(\"Hour averages\")\n",
    "pd.DataFrame.from_dict(average_hour, orient='index')[0].plot()\n",
    "plt.grid(True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3038ca08-b8b5-40b9-9ef5-7cdd18df58e3",
   "metadata": {},
   "source": [
    "Finally, let's put all the transformations together in a single function ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f75f40-2eed-4819-9e02-0056cdb4d24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareData(series, lag_start, lag_end, test_size, target_encoding=False):\n",
    "    \"\"\"\n",
    "        series: pd.DataFrame\n",
    "            dataframe with timeseries\n",
    "\n",
    "        lag_start: int\n",
    "            initial step back in time to slice target variable \n",
    "            example - lag_start = 1 means that the model \n",
    "                      will see yesterday's values to predict today\n",
    "\n",
    "        lag_end: int\n",
    "            final step back in time to slice target variable\n",
    "            example - lag_end = 4 means that the model \n",
    "                      will see up to 4 days back in time to predict today\n",
    "\n",
    "        test_size: float\n",
    "            size of the test dataset after train/test split as percentage of dataset\n",
    "\n",
    "        target_encoding: boolean\n",
    "            if True - add target averages to the dataset\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # copy of the initial dataset\n",
    "    data = pd.DataFrame(series.copy())\n",
    "    data.columns = [\"y\"]\n",
    "    \n",
    "    # lags of series\n",
    "    for i in range(lag_start, lag_end):\n",
    "        data[\"lag_{}\".format(i)] = data.y.shift(i)\n",
    "    \n",
    "    # datetime features\n",
    "    data.index = pd.to_datetime(data.index)\n",
    "    data[\"hour\"] = data.index.hour\n",
    "    data[\"weekday\"] = data.index.weekday\n",
    "    data['is_weekend'] = data.weekday.isin([5,6])*1\n",
    "    \n",
    "    if target_encoding:\n",
    "        # calculate averages on train set only\n",
    "        test_index = int(len(data.dropna())*(1-test_size))\n",
    "        data['weekday_average'] = list(map(code_mean(data[:test_index], 'weekday', \"y\").get, data.weekday))\n",
    "        data[\"hour_average\"] = list(map(code_mean(data[:test_index], 'hour', \"y\").get, data.hour))\n",
    "\n",
    "        # frop encoded variables \n",
    "        data.drop([\"hour\", \"weekday\"], axis=1, inplace=True)\n",
    "    \n",
    "    # train-test split\n",
    "    y = data.dropna().y\n",
    "    X = data.dropna().drop(['y'], axis=1)\n",
    "    X_train, X_test, y_train, y_test = timeseries_train_test_split(X, y, test_size=test_size)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "X_train, X_test, y_train, y_test = prepareData(ads.Ads, lag_start=6, lag_end=25, test_size=0.3, target_encoding=True)\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "plotModelResults(lr, X_train=X_train_scaled, X_test=X_test_scaled, plot_intervals=True, plot_anomalies=True)\n",
    "plotCoefficients(lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73d8433-decc-48a5-9b76-622d96a5b59b",
   "metadata": {},
   "source": [
    "We see some overfitting! Hour_average was so great in the training dataset that the model decided to concentrate all of its forces on it. As a result, the quality of prediction dropped. This problem can be solved in a variety of ways; for example, we can calculate the target encoding not for the whole train set, but for some window instead. That way, encodings from the last observed window will most likely better describe the current series state. Alternatively, we can just drop it manually since we are sure that it makes things only worse in this case.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8347910-79d5-495d-a955-9021e9fb4660",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test =\\\n",
    "prepareData(ads.Ads, lag_start=6, lag_end=25, test_size=0.3, target_encoding=False)\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3e01bc-1eba-47af-b616-b5711b9aa270",
   "metadata": {},
   "source": [
    "Regularization and feature selection\n",
    "As we already know, not all features are equally healthy -- some may lead to overfitting while others should be removed. Besides manual inspection, we can apply regularization. Two of the most popular regression models with regularization are Ridge and Lasso regressions. They both add some more constrains to our loss function.\n",
    "\n",
    "In the case of Ridge regression, those constraints are the sum of squares of the coefficients multiplied by the regularization coefficient. The bigger the coefficient a feature has, the bigger our loss will be. Hence, we will try to optimize the model while keeping the coefficients fairly low.\n",
    "\n",
    "As a result of this L2\n",
    " regularization, we will have higher bias and lower variance, so the model will generalize better (at least that's what we hope will happen).\n",
    "\n",
    "The second regression model, Lasso regression, adds to the loss function, not squares, but absolute values of the coefficients. As a result, during the optimization process, coefficients of unimportant features may become zeroes, which allows for automated feature selection. This regularization type is called L1\n",
    ".\n",
    "\n",
    "First, let's make sure that we have features to drop and that the data has highly correlated features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85995fe3-3d5f-4ead-810a-b778d8a6b796",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(X_train.corr());\n",
    "\n",
    "from sklearn.linear_model import LassoCV, RidgeCV\n",
    "\n",
    "ridge = RidgeCV(cv=tscv)\n",
    "ridge.fit(X_train_scaled, y_train)\n",
    "\n",
    "plotModelResults(ridge, \n",
    "                 X_train=X_train_scaled, \n",
    "                 X_test=X_test_scaled, \n",
    "                 plot_intervals=True, plot_anomalies=True)\n",
    "plotCoefficients(ridge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a5d7a4-fd9f-4c0a-b868-74e69cf1c168",
   "metadata": {},
   "source": [
    "We can clearly see some coefficients are getting closer and closer to zero (though they never actually reach it) as their importance in the model drops.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501d9229-efe4-4e97-910d-023a2571889f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = LassoCV(cv=tscv)\n",
    "lasso.fit(X_train_scaled, y_train)\n",
    "\n",
    "plotModelResults(lasso, \n",
    "                 X_train=X_train_scaled, \n",
    "                 X_test=X_test_scaled, \n",
    "                 plot_intervals=True, plot_anomalies=True)\n",
    "plotCoefficients(lasso)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38ee459-6c06-411d-97e2-fc266dd13923",
   "metadata": {},
   "source": [
    "Lasso regression turned out to be more conservative; it removed 23-rd lag from the most important features and dropped 5 features completely, which only made the quality of prediction better.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a3ce98-0a2f-4e4c-b84c-7335b39ac74f",
   "metadata": {},
   "source": [
    "Boosting\n",
    "Why shouldn't we try XGBoost now?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d87c546-bb24-4858-9d8d-53e04bcd16c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor \n",
    "\n",
    "xgb = XGBRegressor()\n",
    "xgb.fit(X_train_scaled, y_train)\n",
    "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bytree=1, gamma=0, importance_type='gain',\n",
    "       learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
    "       min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
    "       nthread=None, objective='reg:linear', random_state=0, reg_alpha=0,\n",
    "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n",
    "       subsample=1)\n",
    "plotModelResults(xgb, \n",
    "                 X_train=X_train_scaled, \n",
    "                 X_test=X_test_scaled, \n",
    "                 plot_intervals=True, plot_anomalies=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddb3f89-175e-4fc2-b43b-3763890babef",
   "metadata": {},
   "source": [
    "We have a winner! This is the smallest error on the test set among all the models we've tried so far.\n",
    "\n",
    "But, this victory is decieving, and it might not be the brightest idea to fit xgboost as soon as you get your hands on time series data. Generally, tree-based models handle trends in data poorly when compared with linear models. In that case, you would have to detrend your series first or use some tricks to make the magic happen. Ideally, you can make the series stationary and then use XGBoost. For example, you can forecast trend separately with a linear model and then add predictions from xgboost to get a final forecast.\n",
    "\n",
    "Conclusion\n",
    "We discussed different time series analysis and prediction methods. Unfortunately, or maybe luckily, there is no one way to solve these kind of problems. Methods developed in the 1960s (and some even in the beginning of the 21st century) are still popular, along with LSTMs and RNNs (not covered in this article). This is partially related to the fact that the prediction task, like any other data-related task, requires creativity in so many aspects and definitely requires research. In spite of the large number of formal quality metrics and approaches to parameters estimation, it is often necessary to try something different for each time series. Last but not least, the balance between quality and cost is important. As a good example, the SARIMA model can produce spectacular results after tuning but can require many hours of tambourine dancing time series manipulation while a simple linear regression model can be built in 10 minutes and can achieve more or less comparable results.\n",
    "\n",
    "Useful resources\n",
    "Online textbook for the advanced statistical forecasting course at Duke University - covers various smoothing techniques in detail along with linear and ARIMA models\n",
    "Comparison of ARIMA and Random Forest time series models for prediction of avian influenza H5N1 outbreaks - one of a few cases where using random forest for time series forecasting is actively defended\n",
    "Time Series Analysis (TSA) in Python - Linear Models to GARCH - applying the ARIMA models family to the task of modeling financial indicators (by Brian Christopher)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
